---
---


@article{intConf14,
  title     = {Real-Time Electromyogram-Based Facial Expression Recognition Using Riemannian Geometry Features for VR Applications},
  author    = {Cha, Ho-Seung and Choi, Seong-Jun and Im, Chang-Hwan},
  journal   = {41st International Conference of the IEEE EMBS},
  volume    = {8},
  pages     = {62065-62075},
  year      = {2019},
  publisher = {Berlin, Germany, July 26},
  abstract  = {Facial expression recognition (FER) system has been generally studied using optical cameras; however, the performance of this system can be limited while users are wearing head-mounted display (HMD) because users’ faces are largely occluded by the HMD. In this study, we proposed a facial electromyography (fEMG)-based FER system based on Riemannian manifolds-based approach, to reduce the training dataset as well as to enhance the FER performance. Our experiments with 42 participants showed an average classification accuracy as high as 85.01% in recognizing eleven facial expressions with only a single training dataset. We further developed an online FER system that could animate a virtual avatar’s expression reflecting the user’s facial expression in real time, showing that our system could be potentially used for practical social VR applications such as social network service or virtual training.},
  html      = {https://embs.papercept.net/conferences/conferences/EMBC19/program/EMBC19_ContentListWeb_4.html}
}

@article{intConf13,
  title     = {New Strategy for Minimizing Training Time In EMG-Based Facial Expression Recognition for Virtual Reality Applications},
  author    = {Ho-Seung Cha and Chang-Hwan Im},
  journal   = {SMIT2018-IBEC2018 Joint Conference},
  volume    = {8},
  pages     = {62065-62075},
  year      = {2018},
  publisher = {Seoul, South Korea, November 9, 2018}
}
@article{intConf12,
  title     = {User Authentication for Virtual Reality Applications Based on Facial EMG Induced by Facial Expression Changes},
  author    = {Seongjun Choi and Ho-Seung Cha and Chang-Hwan Im},
  journal   = {40th International Conference of the IEEE EMBS},
  volume    = {8},
  pages     = {62065-62075},
  year      = {2018},
  publisher = {Honolulu, USA, July 18},
  abstract  = {Conventional user authentication methods based on password inputted by a controller or a touch pad are generally time-consuming and sometimes cumbersome when a user is wearing virtual reality (VR) devices. Besides, it is also difficult to use camera-based biometric authentication because the user’s face is occluded by VR devices. In this study, we propose a new user authentication system based on facial EMG (fEMG) recorded from electrodes attached on the VR frame. In the preliminary experiment, we tried to distinguish a person out of 15 participants using fEMG signals recorded while the participants were making 11 different facial expressions. The results showed that the ‘happy expression’ yielded the highest classification accuracy of 94.72%, demonstrating that our method has the potential to be used as an intuitive and convenient method for user authentication in VR environments.},
  html      = {https://embs.papercept.net/conferences/conferences/EMBC18/program/EMBC18_ContentListWeb_2.html}
}
@article{intConf11,
  title     = {Prediction of individual user’s suitability for passive BCI applications using short resting EEG recordings},
  author    = {Ho-Seung Cha and Chang-Hwan Im},
  journal   = {7th International BCI Meeting},
  volume    = {8},
  pages     = {62065-62075},
  year      = {2018},
  publisher = {Pacific Grove, California, USA, May 22},
  abstract  = {With the recent development of low-cost wearable electroencephalogram (EEG) recording systems, passive brain–computer interface (pBCI) applications are being actively studied for a variety of application areas, such as education, entertainment, and healthcare. Various EEG features have been employed for the implementation of pBCI applications; however, it is frequently reported that some individuals have difficulty fully enjoying the pBCI applications because the dynamic ranges of their EEG features (i.e., its amplitude variability over time) were too small to be used in the practical applications. Conducting preliminary experiments to search for the individualized EEG features associated with different mental states can partly circumvent this issue; however, these time-consuming experiments were not necessary for the majority of users whose dynamic ranges of EEG features are large enough to be used for pBCI applications. In this study, we tried to predict an individual user’s dynamic ranges of the EEG features that are most widely employed for pBCI applications from resting-state EEG (RS-EEG), with the ultimate goal of identifying individuals who might need additional calibration to become suitable for the pBCI applications. We employed a machine learning-based regression model to predict the dynamic ranges of three widely used EEG features known to be associated with the brain states of valence, relaxation, and concentration. Our results showed that the dynamic ranges of EEG features could be predicted with normalized root mean squared errors of 0.2323, 0.1820, and 0.1562, respectively, demonstrating the possibility of predicting the dynamic ranges of the EEG features for pBCI applications using short resting EEG data. },
  html      = {https://docplayer.net/85041633-Abstract-book-bcis-not-getting-lost-in-translation-seventh-international-bci-meeting.html}
}
@article{intConf10,
  title     = {Real-time Recognition of Lip Gestures Based on Facial EMG},
  author    = {Ho-Seung Cha, Won-Du Chang and Chang-Hwan Im},
  journal   = {3rd Annual International Biomedical Engineering Conference},
  volume    = {8},
  pages     = {62065-62075},
  year      = {2016},
  publisher = {Seoul, Korea November 11}
}
@article{intConf9,
  title     = {A Real-Time Lip Gesture Recognition System using Facial EMG},
  author    = {Ho-Seung Cha and Won-Du Chang and Chang-Hwan Im},
  journal   = {38th Annual International Conference of the IEEE EMBS},
  volume    = {8},
  pages     = {62065-62075},
  year      = {2016},
  publisher = {Orlando, Florida, USA, August 19},
  abstract  = {Recognizing lip gesture has been a widely studied research topic for human-computer interaction (HCI), for which optical sensors or cameras have been generally used. However, the cameras are sensitive to lightening conditions, and the movements of users are limited because of the angle of view of the cameras. Facial electromyography (fEMG) is an alternative approach for the lip gesture recognition. In this study, we suggested a new lip gesture recognition system using fEMG. The system could classify seven lip gestures with high classification accuracies of 91.79% and 87.14% in offline and online tests, when only four EMG channels were used. Our result shows that this system can be potentially used for various HCI applications such as enhancement of silent speech recognition and avatar control in a virtual reality environment, which can be used for entertainment or education in real-life.},
  html      = {https://embs.papercept.net/conferences/conferences/EMBC16/program/EMBC16_ContentListWeb_3.html}
}
@article{intConf8,
  title     = {Improved Electrooculogram-based Eye-writing Recognition Using a New Feature Extraction Method},
  author    = {Won-Du Chang and Ho-Seung Cha and Chang-Hwan Im},
  journal   = {2nd Annual International Biomedical Engineering Conference},
  volume    = {8},
  pages     = {62065-62075},
  year      = {2015},
  publisher = {Gyeongju, Korea, November 12}
}
@article{intConf7,
  title     = {EEG-Based Neurocinematics: Potential Brain Indices for Rating Films},
  author    = {Ho-Seung Cha and Won-Du Chang and Young-Seok Shin and Dongpyo Jang and Chang-Hwan Im},
  journal   = {37th Annual International Conference of the IEEE EMBS},
  volume    = {8},
  pages     = {62065-62075},
  year      = {2015},
  publisher = {Milano, Italy, Aug 25 - 29, 2015},
  abstract  = {Neurocinematics is an emerging research discipline that studies audiences’ cognitive and affective responses to cinematic stimuli. To date, functional magnetic resonance imaging (fMRI) has been the most widely used research tool for neurocinematics studies; however, recent studies have shown that electroencephalography (EEG) can also be a promising tool for neurocinematics studies thanks to its excellent temporal resolution. In this study, we proposed two EEG-based film rating indices named “empathy index” and “reactivity index” that were devised to measure empathy and reactivity of audiences during movie screening.},
  html      = {https://embs.papercept.net/conferences/scripts/rtf/EMBC15_ContentListWeb_4.html}
}
@article{intConf6,
  title     = {An Emergency Call System for Patients with Severe ALS Using Less-Stimulating SSVEP-Based Brain Switch},
  author    = {Jeong-Hwan Lim and Yong-Wook Kim and Chang-Hee Han and Ho-Seung Cha and Chang-Hwan Im},
  journal   = {37th Annual International Conference of the IEEE EMBS},
  volume    = {8},
  pages     = {62065-62075},
  year      = {2015},
  publisher = {Milano, Italy, Aug 25 - 29, 2015},
  abstract  = {In the present study, we developed an emergency call system for patients with severe amyotrophic lateral sclerosis (ALS) using a steady-state visual evoked potential (SSVEP) – based brain switch system. The brain switch system adopted a chromatic visual stimulus, which proved to be less stimulating and thus more adequate for daily-life use. Online experiments were conducted with five healthy subjects and two patients with severe ALS, and the results showed that the average time needed to turn on the brain switch was 8.9 s, and the brain switch did not operate for 166.4 s while the participants did not gaze at the stimulus. Moreover, we evaluated the test-retest reliability for long-term use of the system.},
  html      = {https://embs.papercept.net/conferences/scripts/rtf/EMBC15_ContentListWeb_4.html}
}
@article{intConf5,
  title     = {A Novel Method to Detect Eye Blink Artifacts from a Frontal Single-Channel Electroencephalogram},
  author    = {Won-Du Chang and Ho-Seung Cha and Chang-Hwan Im},
  journal   = {International Biomedical Engineering Conference (IBEC) 2014},
  volume    = {8},
  pages     = {62065-62075},
  year      = {2014},
  publisher = {Gwangju, Nov 20, 2014}
}
@article{intConf4,
  title     = {A New Method for Detecting Eye-Blink Artifacts from a single-Channel Electroencephalogram},
  author    = {Won-Du Chang and Ho-Seung Cha and Chang-Hwan Im Kang and Chang-Hwan Im},
  journal   = {36th Annual International Conference of the IEEE EMBS},
  volume    = {8},
  pages     = {62065-62075},
  year      = {2014},
  publisher = {Chicago, Illinois USA, Aug 2014},
  abstract  = {It is well known that eye blinks are one of the largest artifact sources contaminating frontal channel electroencephalogram (EEG) data. Therefore, detecting and rejecting eye blink artifacts is regarded as a common procedure for improving the quality of EEG data. This paper proposes a novel method to detect eye blink artifacts from a single-channel frontal EEG signal.},
  html      = {https://embs.papercept.net/conferences/scripts/rtf/EMBC14_ContentListWeb_1.html}
}
@article{intConf3,
  title     = {Enhanced Template Matching Using Dynamic Positional Warping for Pattern Recognition in Electroencephalogram},
  author    = {Won-Du Chang and Ho-Seung Cha and Chang-Hwan Im},
  journal   = {36th Annual International Conference of the IEEE EMBS},
  volume    = {8},
  pages     = {62065-62075},
  year      = {2014},
  publisher = {Chicago, Illinois USA, Aug 2014},
  abstract  = {Since electroencephalogram (EEG) is often contaminated by other physiological/ pathological artifacts, automatic detection of these artifacts is important to enhance the quality of the raw EEG signals. This paper proposes a novel approach to improve the accuracy of conventional template matching methods by adopting the dynamic positional warping technique, developed recently for handwriting pattern analysis.},
  html      = {https://embs.papercept.net/conferences/scripts/rtf/EMBC14_ContentListWeb_1.html}
}
@article{intConf2,
  title     = {Implementation of a Steady State Visual Evoked Potential (SSVEP)-Based Online Brain-Switch System Using a Chromatic Stimulus},
  author    = {Jeong-Hwan Lim and Jun-Hak Lee and Yong-Wook Kim and Han Choi and Chang-Hee Han and Ho-Seung Cha and Chang-Hwan Im},
  journal   = {36th Annual International Conference of the IEEE EMBS},
  volume    = {8},
  pages     = {62065-62075},
  year      = {2014},
  publisher = {Chicago, Illinois USA, Aug 2014},
  abstract  = {In the present study, we developed a steady-state visual evoked potential (SSVEP)–based brain switch system adopting a chromatic visual stimulus, which is less stimulating and thus more adequate for daily-life use. Preliminary online experiments were conducted with two healthy subjects and a patient with ALS, and the results showed that the average time needed to turn on the brain switch was 11.6 s. Moreover, the brain switch stayed being idle state for 115.6 s while the participants did not gaze at the stimulus, demonstrating the possibility of the “less stimulating” SSVEP brain switch system.},
  html      = {https://embs.papercept.net/conferences/scripts/rtf/EMBC14_ContentListWeb_2.html}
}
@article{intConf1,
  title     = {A Transient Visual Evoked Potential (tVEP)-based Brain Switch System},
  author    = {Ho-Seung Cha and Jeong-Hwan Lim and Chang-Hee Han and Han-Jeong Hwang and Won-Du Chang and Chang-Hwan Im},
  journal   = {36th Annual International Conference of the IEEE EMBS},
  volume    = {8},
  pages     = {62065-62075},
  year      = {2014},
  publisher = {Chicago, Illinois USA, Aug 2014},
  abstract  = {Brain switch systems based on steady-state visual evoked potential (SSVEP) and P300 require users to stare at the quickly flickering light stimuli, which makes the users easily tired. To circumvent this, we proposed a new transient VEP (tVEP)-based brain switch system by using a chromatic stimulus flickering at less than 1 Hz. Most subjects felt that the new stimulus was much more comfortable than the conventional checkerboard stimulus. Online experiments showed that the average time to turn on the brain switch system was 13.69 s, whereas the switch stayed in ‘off’ state for 122.65 s while the users watched a movie clip played at a different monitor, demonstrating the feasibility and usability of our brain switch system in practical scenarios.},
  html      = {https://embs.papercept.net/conferences/scripts/rtf/EMBC14_ContentListWeb_2.html}
}

