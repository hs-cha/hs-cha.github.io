<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Hoseung  Cha | presentations</title>
<meta name="description" content="The blog posts are being prepared
">

<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />
<script defer src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha512-/DXTXr6nQodMUiq+IUJYCt2PPOUjrHJ9wFrqpJ3XkgPNOZVfMok7cRw6CSxyCQxXn6ozlESsSh1/sMCTF1rL/g==" crossorigin="anonymous"></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script defer src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js"  integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/presentations/">

<!-- Open Graph -->


<!-- Load Common JS -->
<script defer src="/assets/js/common.js"></script>

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />


<!-- Load MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>



<!-- Load Mansory & imagesLoaded -->
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="" crossorigin="anonymous"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>

<!-- Project Cards Layout -->
<script defer type="text/javascript">
  // Init Masonry
  var $grid = $('.grid').masonry({
    gutter: 10,
    horizontalOrder: true,
    itemSelector: '.grid-item',
  });
  // layout Masonry after each image loads
  $grid.imagesLoaded().progress( function() {
    $grid.masonry('layout');
  });
</script>






  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light bg-white navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="http://hs-cha.github.io/">
       <span class="font-weight-bold">Hoseung</span>   Cha
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          <!--  -->
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/cv/">
                cv
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/patents/">
                patents
                
              </a>
          </li>
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/presentations/">
                presentations
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <!-- <header class="post-header">
    <h1 class="post-title">Presentations</h1>
    <p class="post-description">publications by categories in reversed chronological order.</p>
  </header> -->

  <article>
    <header class="post-header">
    <h1 class="post-title">International Conferences</h1>
    <!-- <p class="post-description">Ten papers were published in SCI journals and one was published in a non-SCI journal</p> -->
</header>

<div class="publications">


  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="intConf15" class="col-sm-8">
    
      <div class="title">Development of an Online Home Appliance Control System Using Augmented Reality and an SSVEP-Based Brain-Computer Interface</div>
      <div class="author">
        
          
            
              
                
                  Park, Seonghun,
                
              
            
          
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  Kwon, Jinuk,
                
              
            
          
        
          
            
              
                
                  Kim, Hodam,
                
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>International Winter Workshop on Brain-Computer Interface (BCI)</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/document/9061633" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this study, we implemented a new home appliance control system by combining a steady-state visual evoked potential (SSVEP)-based brain-computer interface (BCI), augmented reality (AR), and internet of things (IoT) technologies. The visual stimuli were presented on a see-through head-mounted display (HMD), while the recorded brain activity was analyzed to classify the control command, and the home appliances were controlled through IoT. The average classification accuracy of the SSVEP-BCI-based control system was 92.8%, with an information transfer rate (ITR) of 37.4 bits/min. The proposed system exhibited an excellent performance, surpassing the best results reported in previous studies regarding external device control based on BCI using an HMD as rendering device.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="intConf14" class="col-sm-8">
    
      <div class="title">Real-Time Electromyogram-Based Facial Expression Recognition Using Riemannian Geometry Features for VR Applications</div>
      <div class="author">
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  Choi, Seong-Jun,
                
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>41st International Conference of the IEEE EMBS</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://embs.papercept.net/conferences/conferences/EMBC19/program/EMBC19_ContentListWeb_4.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Facial expression recognition (FER) system has been generally studied using optical cameras; however, the performance of this system can be limited while users are wearing head-mounted display (HMD) because users’ faces are largely occluded by the HMD. In this study, we proposed a facial electromyography (fEMG)-based FER system based on Riemannian manifolds-based approach, to reduce the training dataset as well as to enhance the FER performance. Our experiments with 42 participants showed an average classification accuracy as high as 85.01% in recognizing eleven facial expressions with only a single training dataset. We further developed an online FER system that could animate a virtual avatar’s expression reflecting the user’s facial expression in real time, showing that our system could be potentially used for practical social VR applications such as social network service or virtual training.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="intConf13" class="col-sm-8">
    
      <div class="title">New Strategy for Minimizing Training Time In EMG-Based Facial Expression Recognition for Virtual Reality Applications</div>
      <div class="author">
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>SMIT2018-IBEC2018 Joint Conference</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="intConf12" class="col-sm-8">
    
      <div class="title">User Authentication for Virtual Reality Applications Based on Facial EMG Induced by Facial Expression Changes</div>
      <div class="author">
        
          
            
              
                
                  Choi, Seongjun,
                
              
            
          
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>40th International Conference of the IEEE EMBS</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://embs.papercept.net/conferences/conferences/EMBC18/program/EMBC18_ContentListWeb_2.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Conventional user authentication methods based on password inputted by a controller or a touch pad are generally time-consuming and sometimes cumbersome when a user is wearing virtual reality (VR) devices. Besides, it is also difficult to use camera-based biometric authentication because the user’s face is occluded by VR devices. In this study, we propose a new user authentication system based on facial EMG (fEMG) recorded from electrodes attached on the VR frame. In the preliminary experiment, we tried to distinguish a person out of 15 participants using fEMG signals recorded while the participants were making 11 different facial expressions. The results showed that the ‘happy expression’ yielded the highest classification accuracy of 94.72%, demonstrating that our method has the potential to be used as an intuitive and convenient method for user authentication in VR environments.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="intConf11" class="col-sm-8">
    
      <div class="title">Prediction of individual user’s suitability for passive BCI applications using short resting EEG recordings</div>
      <div class="author">
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>7th International BCI Meeting</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://docplayer.net/85041633-Abstract-book-bcis-not-getting-lost-in-translation-seventh-international-bci-meeting.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>With the recent development of low-cost wearable electroencephalogram (EEG) recording systems, passive brain–computer interface (pBCI) applications are being actively studied for a variety of application areas, such as education, entertainment, and healthcare. Various EEG features have been employed for the implementation of pBCI applications; however, it is frequently reported that some individuals have difficulty fully enjoying the pBCI applications because the dynamic ranges of their EEG features (i.e., its amplitude variability over time) were too small to be used in the practical applications. Conducting preliminary experiments to search for the individualized EEG features associated with different mental states can partly circumvent this issue; however, these time-consuming experiments were not necessary for the majority of users whose dynamic ranges of EEG features are large enough to be used for pBCI applications. In this study, we tried to predict an individual user’s dynamic ranges of the EEG features that are most widely employed for pBCI applications from resting-state EEG (RS-EEG), with the ultimate goal of identifying individuals who might need additional calibration to become suitable for the pBCI applications. We employed a machine learning-based regression model to predict the dynamic ranges of three widely used EEG features known to be associated with the brain states of valence, relaxation, and concentration. Our results showed that the dynamic ranges of EEG features could be predicted with normalized root mean squared errors of 0.2323, 0.1820, and 0.1562, respectively, demonstrating the possibility of predicting the dynamic ranges of the EEG features for pBCI applications using short resting EEG data. </p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2016</h2>
  <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="intConf10" class="col-sm-8">
    
      <div class="title">Real-time Recognition of Lip Gestures Based on Facial EMG</div>
      <div class="author">
        
          
            
              
                
                  Ho-Seung Cha, Won-Du Chang,
                
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>3rd Annual International Biomedical Engineering Conference</em>
      
      
        2016
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="intConf9" class="col-sm-8">
    
      <div class="title">A Real-Time Lip Gesture Recognition System using Facial EMG</div>
      <div class="author">
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  Chang, Won-Du,
                
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>38th Annual International Conference of the IEEE EMBS</em>
      
      
        2016
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://embs.papercept.net/conferences/conferences/EMBC16/program/EMBC16_ContentListWeb_3.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recognizing lip gesture has been a widely studied research topic for human-computer interaction (HCI), for which optical sensors or cameras have been generally used. However, the cameras are sensitive to lightening conditions, and the movements of users are limited because of the angle of view of the cameras. Facial electromyography (fEMG) is an alternative approach for the lip gesture recognition. In this study, we suggested a new lip gesture recognition system using fEMG. The system could classify seven lip gestures with high classification accuracies of 91.79% and 87.14% in offline and online tests, when only four EMG channels were used. Our result shows that this system can be potentially used for various HCI applications such as enhancement of silent speech recognition and avatar control in a virtual reality environment, which can be used for entertainment or education in real-life.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2015</h2>
  <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="intConf8" class="col-sm-8">
    
      <div class="title">Improved Electrooculogram-based Eye-writing Recognition Using a New Feature Extraction Method</div>
      <div class="author">
        
          
            
              
                
                  Chang, Won-Du,
                
              
            
          
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>2nd Annual International Biomedical Engineering Conference</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="intConf7" class="col-sm-8">
    
      <div class="title">EEG-Based Neurocinematics: Potential Brain Indices for Rating Films</div>
      <div class="author">
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  Chang, Won-Du,
                
              
            
          
        
          
            
              
                
                  Shin, Young-Seok,
                
              
            
          
        
          
            
              
                
                  Jang, Dongpyo,
                
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>37th Annual International Conference of the IEEE EMBS</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://embs.papercept.net/conferences/scripts/rtf/EMBC15_ContentListWeb_4.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Neurocinematics is an emerging research discipline that studies audiences’ cognitive and affective responses to cinematic stimuli. To date, functional magnetic resonance imaging (fMRI) has been the most widely used research tool for neurocinematics studies; however, recent studies have shown that electroencephalography (EEG) can also be a promising tool for neurocinematics studies thanks to its excellent temporal resolution. In this study, we proposed two EEG-based film rating indices named “empathy index” and “reactivity index” that were devised to measure empathy and reactivity of audiences during movie screening.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="intConf6" class="col-sm-8">
    
      <div class="title">An Emergency Call System for Patients with Severe ALS Using Less-Stimulating SSVEP-Based Brain Switch</div>
      <div class="author">
        
          
            
              
                
                  Lim, Jeong-Hwan,
                
              
            
          
        
          
            
              
                
                  Kim, Yong-Wook,
                
              
            
          
        
          
            
              
                
                  Han, Chang-Hee,
                
              
            
          
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>37th Annual International Conference of the IEEE EMBS</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://embs.papercept.net/conferences/scripts/rtf/EMBC15_ContentListWeb_4.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In the present study, we developed an emergency call system for patients with severe amyotrophic lateral sclerosis (ALS) using a steady-state visual evoked potential (SSVEP) – based brain switch system. The brain switch system adopted a chromatic visual stimulus, which proved to be less stimulating and thus more adequate for daily-life use. Online experiments were conducted with five healthy subjects and two patients with severe ALS, and the results showed that the average time needed to turn on the brain switch was 8.9 s, and the brain switch did not operate for 166.4 s while the participants did not gaze at the stimulus. Moreover, we evaluated the test-retest reliability for long-term use of the system.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2014</h2>
  <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="intConf5" class="col-sm-8">
    
      <div class="title">A Novel Method to Detect Eye Blink Artifacts from a Frontal Single-Channel Electroencephalogram</div>
      <div class="author">
        
          
            
              
                
                  Chang, Won-Du,
                
              
            
          
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>International Biomedical Engineering Conference (IBEC) 2014</em>
      
      
        2014
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="intConf4" class="col-sm-8">
    
      <div class="title">A New Method for Detecting Eye-Blink Artifacts from a single-Channel Electroencephalogram</div>
      <div class="author">
        
          
            
              
                
                  Chang, Won-Du,
                
              
            
          
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  Kang, Chang-Hwan Im,
                
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>36th Annual International Conference of the IEEE EMBS</em>
      
      
        2014
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://embs.papercept.net/conferences/scripts/rtf/EMBC14_ContentListWeb_1.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>It is well known that eye blinks are one of the largest artifact sources contaminating frontal channel electroencephalogram (EEG) data. Therefore, detecting and rejecting eye blink artifacts is regarded as a common procedure for improving the quality of EEG data. This paper proposes a novel method to detect eye blink artifacts from a single-channel frontal EEG signal.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="intConf3" class="col-sm-8">
    
      <div class="title">Enhanced Template Matching Using Dynamic Positional Warping for Pattern Recognition in Electroencephalogram</div>
      <div class="author">
        
          
            
              
                
                  Chang, Won-Du,
                
              
            
          
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>36th Annual International Conference of the IEEE EMBS</em>
      
      
        2014
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://embs.papercept.net/conferences/scripts/rtf/EMBC14_ContentListWeb_1.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Since electroencephalogram (EEG) is often contaminated by other physiological/ pathological artifacts, automatic detection of these artifacts is important to enhance the quality of the raw EEG signals. This paper proposes a novel approach to improve the accuracy of conventional template matching methods by adopting the dynamic positional warping technique, developed recently for handwriting pattern analysis.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="intConf2" class="col-sm-8">
    
      <div class="title">Implementation of a Steady State Visual Evoked Potential (SSVEP)-Based Online Brain-Switch System Using a Chromatic Stimulus</div>
      <div class="author">
        
          
            
              
                
                  Lim, Jeong-Hwan,
                
              
            
          
        
          
            
              
                
                  Lee, Jun-Hak,
                
              
            
          
        
          
            
              
                
                  Kim, Yong-Wook,
                
              
            
          
        
          
            
              
                
                  Choi, Han,
                
              
            
          
        
          
            
              
                
                  Han, Chang-Hee,
                
              
            
          
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>36th Annual International Conference of the IEEE EMBS</em>
      
      
        2014
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://embs.papercept.net/conferences/scripts/rtf/EMBC14_ContentListWeb_2.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In the present study, we developed a steady-state visual evoked potential (SSVEP)–based brain switch system adopting a chromatic visual stimulus, which is less stimulating and thus more adequate for daily-life use. Preliminary online experiments were conducted with two healthy subjects and a patient with ALS, and the results showed that the average time needed to turn on the brain switch was 11.6 s. Moreover, the brain switch stayed being idle state for 115.6 s while the participants did not gaze at the stimulus, demonstrating the possibility of the “less stimulating” SSVEP brain switch system.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="intConf1" class="col-sm-8">
    
      <div class="title">A Transient Visual Evoked Potential (tVEP)-based Brain Switch System</div>
      <div class="author">
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  Lim, Jeong-Hwan,
                
              
            
          
        
          
            
              
                
                  Han, Chang-Hee,
                
              
            
          
        
          
            
              
                
                  Hwang, Han-Jeong,
                
              
            
          
        
          
            
              
                
                  Chang, Won-Du,
                
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>36th Annual International Conference of the IEEE EMBS</em>
      
      
        2014
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://embs.papercept.net/conferences/scripts/rtf/EMBC14_ContentListWeb_2.html" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Brain switch systems based on steady-state visual evoked potential (SSVEP) and P300 require users to stare at the quickly flickering light stimuli, which makes the users easily tired. To circumvent this, we proposed a new transient VEP (tVEP)-based brain switch system by using a chromatic stimulus flickering at less than 1 Hz. Most subjects felt that the new stimulus was much more comfortable than the conventional checkerboard stimulus. Online experiments showed that the average time to turn on the brain switch system was 13.69 s, whereas the switch stayed in ‘off’ state for 122.65 s while the users watched a movie clip played at a different monitor, demonstrating the feasibility and usability of our brain switch system in practical scenarios.</p>
    </div>
    
  </div>
</div>
</li></ol>


</div>

<header class="post-header">
    <h1 class="post-title"><br /><br />Domestic Conferences</h1>
    <!-- <p class="post-description">Two papers were under review and one was under preparation.</p> -->
</header>

<div class="publications">


  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="domConf17" class="col-sm-8">
    
      <div class="title">Development of a Facial Motion Capture System Based on Facial Electromyogram Recorded around the Eyes for Social Virtual Reality 
Applications</div>
      <div class="author">
        
          
            
              
                
                  Kim, Chunghwan,
                
              
            
          
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>The Institute of Electronics and Information Engineers</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="domConf16" class="col-sm-8">
    
      <div class="title">Real-time EOG-Based Eye Tracking Method in VR Environment using Arbitrary Multichannel Electrode Configuration</div>
      <div class="author">
        
          
            
              
                
                  Choi, Kang-min,
                
              
            
          
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  Lee, Sangjun,
                
              
            
          
        
          
            
              
                
                  Park, Jimin,
                
              
            
          
        
          
            
              
                
                  Kim, Suhey,
                
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>The Institute of Electronics and Information Engineers</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="domConf15" class="col-sm-8">
    
      <div class="title">New Method for Estimating  Emotion Arousal Changes of a Group of Individuals During Movie Screening Using SSVEP</div>
      <div class="author">
        
          
            
              
                
                  Park, Seonghun,
                
              
            
          
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Korean Society for EEG and Neurophysiology</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="domConf14" class="col-sm-8">
    
      <div class="title">Real-time Electromyogram-Based Facial Expression Recognition Using Riemannian Geometry Features for VR application</div>
      <div class="author">
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  Choi, Seongjun,
                
              
            
          
        
          
            
              
                
                  Kim, Chunghwan,
                
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Engineering in circadian rhythm and ubiquitous healthcare (Uhealthcare)</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="domConf13" class="col-sm-8">
    
      <div class="title">Development of Silent Speech Recognition System Based on Facial Electromyogram Recorded around Eyes for Hands-free Interactions in Virtual Environments</div>
      <div class="author">
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Korean Society of Medical &amp; Biological Engineering (KOSOMBE)</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="domConf12" class="col-sm-8">
    
      <div class="title">User Authentication for Virtual Reality Applications Based on Facial EMG Induced by Facial Expression Changes</div>
      <div class="author">
        
          
            
              
                
                  Choi, Kang-min,
                
              
            
          
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Korean Society of Medical &amp; Biological Engineering (KOSOMBE)</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="domConf11" class="col-sm-8">
    
      <div class="title">Development of Dyslexia Diagnosis System Using Electrooculogram: a Proof-of-concept Study</div>
      <div class="author">
        
          
            
              
                
                  Kim, Jung-Hwan,
                
              
            
          
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  Lee, Seoungjae,
                
              
            
          
        
          
            
              
                
                  Park, Chuljin,
                
              
            
          
        
          
            
              
                
                  Kim, In Young,
                
              
            
          
        
          
            
              
                
                  Park, Se-Keun,
                
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Korean Society of Medical &amp; Biological Engineering (KOSOMBE)</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="domConf10" class="col-sm-8">
    
      <div class="title">Development of Facial Motion Capture Technology Based on Facial Electromyogram Using Deep Learning</div>
      <div class="author">
        
          
            
              
                
                  Choi, Seong-Jun,
                
              
            
          
        
          
            
              
                
                  Kim, Chunghwan,
                
              
            
          
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Korean Society of Medical &amp; Biological Engineering (KOSOMBE)</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="domConf9" class="col-sm-8">
    
      <div class="title">Development of Avatar Expressing Emotions in Real Time Using Facial Electromyogram-based Facial Expression in Virtual Environment</div>
      <div class="author">
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Korean Society of Medical &amp; Biological Engineering (KOSOMBE)</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2017</h2>
  <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="domConf8" class="col-sm-8">
    
      <div class="title">Performance Comparison of Classification Techniques for the Facial Expression Recognition Based on Surface EMG</div>
      <div class="author">
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  Choi, Seong-Jun,
                
              
            
          
        
          
            
              
                
                  Kim, Hodam,
                
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Korean Society of Medical &amp; Biological Engineering (KOSOMBE)</em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2016</h2>
  <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="domConf7" class="col-sm-8">
    
      <div class="title">Neurocinematics: Development of Indices of Evaluating Cinematic Using EEG</div>
      <div class="author">
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  Chang, Won-Du,
                
              
            
          
        
          
            
              
                
                  Shin, Young Seok,
                
              
            
          
        
          
            
              
                
                  Jang, Dong Pyo,
                
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Korean Society of Medical &amp; Biological Engineering (KOSOMBE)</em>
      
      
        2016
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2015</h2>
  <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="domConf6" class="col-sm-8">
    
      <div class="title">An Emergency Call System for Patients with Severe ALS Using Less-Stimulating SSVEP-Based Brain Switch</div>
      <div class="author">
        
          
            
              
                
                  Lim, Jeong-Hwan,
                
              
            
          
        
          
            
              
                
                  Kim, Yong-Wook,
                
              
            
          
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  Han, Chang-Hee,
                
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Korean Society for Computational Neuroscience</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="domConf5" class="col-sm-8">
    
      <div class="title">Electrooculogram-based Real-time Digit Input System</div>
      <div class="author">
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  Lim, JongYoep,
                
              
            
          
        
          
            
              
                
                  Jeon, Da-sol,
                
              
            
          
        
          
            
              
                
                  Chang, Won-Du,
                
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Korean Society of Medical &amp; Biological Engineering (KOSOMBE)</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="domConf4" class="col-sm-8">
    
      <div class="title">Implementation of a Steady State Visual Evoked Potential-based “Less Stimulating” Brain Switch System Using a Chromatic Stimulus</div>
      <div class="author">
        
          
            
              
                
                  Lim, Jeong-Hwan,
                
              
            
          
        
          
            
              
                
                  Kim, Yong-Wook,
                
              
            
          
        
          
            
              
                
                  Lee, Jun-Hak,
                
              
            
          
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Korean Society of Medical &amp; Biological Engineering (KOSOMBE)</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2014</h2>
  <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="domConf3" class="col-sm-8">
    
      <div class="title">Development of the Brain Switch System Using CTVEP</div>
      <div class="author">
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  Lim, Jeong-Hwan,
                
              
            
          
        
          
            
              
                
                  Hwang, Han-Jeong,
                
              
            
          
        
          
            
              
                
                  Han, Chang-Hee,
                
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Korean Society of Medical &amp; Biological Engineering (KOSOMBE)</em>
      
      
        2014
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="domConf2" class="col-sm-8">
    
      <div class="title">A Study on Automatic Detection of Spikes from a Single-Channel Electroencephalogram</div>
      <div class="author">
        
          
            
              
                
                  Chang, Won-Du,
                
              
            
          
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Korean Society of Medical &amp; Biological Engineering (KOSOMBE)</em>
      
      
        2014
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2013</h2>
  <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-2 abbr">
  
  </div> -->

  <div id="domConf1" class="col-sm-8">
    
      <div class="title">A Transient Visual Evoked Potential (tVEP)-based Brain Switch System</div>
      <div class="author">
        
          
            
              
                <em>Cha, Ho-Seung</em>,
              
            
          
        
          
            
              
                
                  Lim, Jeong-Hwan,
                
              
            
          
        
          
            
              
                
                  Hwang, Han-Jeong,
                
              
            
          
        
          
            
              
                
                  Han, Chang-Hee,
                
              
            
          
        
          
            
              
                
                  and Im, Chang-Hwan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Korean Society of Medical &amp; Biological Engineering (KOSOMBE)</em>
      
      
        2013
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>


</div>

<!-- <header class="post-header">
    <h1 class="post-title"><br/><br/> International Conferences</h1>
    <p class="post-description">publications by categories in reversed chronological order.</p>
</header>


<div class="publications">



</div>  -->

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2020 Hoseung  Cha.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>.

    
  </div>
</footer>



  </body>

</html>
